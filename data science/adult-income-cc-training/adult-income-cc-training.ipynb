{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607925f-4c51-4878-a16a-71d9af6b8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d5668-1781-494a-82c1-975167faf5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform some setup\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import joblib\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT = \"[project]\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "MODEL_NAME = \"adult-income-cc-training-model\"\n",
    "BUCKET_NAME = \"[project]\"\n",
    "GCS_FOLDER = \"adult-income-cc-training-model\"\n",
    "\n",
    "REPO_NAME = 'adult-income-cc-training-repo'\n",
    "IMAGE_NAME = 'adult-income-cc-training-image'\n",
    "JOB_NAME = 'adult-income-cc-training-job'\n",
    "SERVING_CONTAINER_URI = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-13:latest'\n",
    "\n",
    "! gcloud artifacts repositories create $REPO_NAME --repository-format=docker \\\n",
    "--location=$LOCATION --description=\"Docker repository\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016edb6-a29f-4c8f-b7b9-2f88e137911f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure docker auth\n",
    "\n",
    "! gcloud auth configure-docker {LOCATION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f0967-fdb5-4ec2-a005-8ee6666680e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build and push the training image\n",
    "\n",
    "import sys\n",
    "\n",
    "IMAGE_URI = f\"{LOCATION}-docker.pkg.dev/{PROJECT}/{REPO_NAME}/{IMAGE_NAME}\"\n",
    "\n",
    "! docker build . -t $IMAGE_URI\n",
    "! docker push $IMAGE_URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3dd38-9107-4b2e-8e73-5b2ceb04b1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the CustomContainerTrainingJob object\n",
    "\n",
    "# initialize aiplatform\n",
    "aiplatform.init([arguments])\n",
    "\n",
    "# create tge CustomContainerTrainingJob object\n",
    "job = [finish the code]\n",
    "\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb3840-5d41-4653-aeee-d2ea18b011a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the job\n",
    "\n",
    "model = [finish the code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacaf18-4215-4fdf-b13e-77ec2051beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the model to the endpoint\n",
    "endpoint = [finish the code]]\n",
    "\n",
    "print(f'Endpoint ID: {endpoint.resource_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b568866-7b01-4a3e-8812-b769d3a44c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the pickled preprocessing stuff\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "pkls = [\n",
    "    \"scaler.pkl\",\n",
    "    \"label_encoder.pkl\",\n",
    "    \"categorical_encoder.pkl\"\n",
    "]\n",
    "\n",
    "for pkl in pkls:\n",
    "    blob = bucket.blob(f\"{GCS_FOLDER}/{pkl}\")\n",
    "    blob.download_to_filename(pkl)\n",
    "\n",
    "# load the pre-trained ML preprocessing objects (scaler, label_encoder, and categorical_encoder)\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "categorical_encoder = joblib.load('categorical_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22623d-9c84-46b8-86f7-ea1d4c6c2c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# do the prediction\n",
    "\n",
    "# populate the list of instances for prediction\n",
    "instances = [\n",
    "    [39,\"Private\", \"9th\",5,\"Married-civ-spouse\",\"Other-service\",\"Wife\",\"Black\",\"Female\",3411,0,34,\"United-States\"],\n",
    "    [77,\"Private\", \"9th\",5,\"Married-civ-spouse\",\"Priv-house-serv\",\"Wife\",\"Black\",\"Female\",0,0,10,\"United-States\"],\n",
    "    [27,\"Local-gov\",\"HS-grad\",9,\"Married-civ-spouse\",\"Exec-managerial\",\"Husband\",\"White\",\"Male\",0,0,80,\"United-States\"],\n",
    "    [40,\"Private\",\"Masters\",14,\"Married-civ-spouse\",\"Exec-managerial\",\"Husband\",\"White\",\"Male\",0,0,46,\"United-States\"]\n",
    "\n",
    "]\n",
    "\n",
    "# what is this code doing? why does it work?\n",
    "instances_numeric_features = np.array([[instance[0], instance[3], instance[9], instance[10], instance[11]] for instance in instances])\n",
    "instances_scaled_numeric_features = scaler.transform(instances_numeric_features)\n",
    "\n",
    "# what is this code doing? why does it work?\n",
    "instances_categorical_features = np.array([instance[1:3] + instance[4:9] + [instance[12]] for instance in instances])\n",
    "instances_categorical_encoded = categorical_encoder.transform(instances_categorical_features)\n",
    "\n",
    "# what is this code doing?\n",
    "instances_combined = np.hstack((instances_scaled_numeric_features, instances_categorical_encoded))\n",
    "\n",
    "# what is this code doing? why is it important?\n",
    "preprocessed_instances_as_list = instances_combined.tolist()\n",
    "\n",
    "# call the predict method and pass the instances for prediction\n",
    "response = endpoint.predict(instances=preprocessed_instances_as_list)\n",
    "\n",
    "# what is response.predictions?\n",
    "# what is a prediction?\n",
    "# what is argmax doing?\n",
    "# what is inverse_transform doing?\n",
    "for prediction in response.predictions:\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    decoded_label = label_encoder.inverse_transform([predicted_label])[0]\n",
    "    print(f'Predicted Label: {decoded_label}')\n",
    "    print(f'Predicted Probabilities: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3209b-67fc-4b18-8eb3-981054f4dc00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
