{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368f889-9f70-46f7-94ae-cbb7462c15e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff820b-7022-442e-a84e-280e2888435b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perform some setup\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "PROJECT = \"jwd-test-sbcl\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "MODEL_NAME = \"adult-income-ap-training-model\"\n",
    "BUCKET_NAME = \"jwd-test-sbcl\"\n",
    "GCS_FOLDER = \"adult-income-ap-training-model\"\n",
    "\n",
    "JOB_NAME = \"adult-income-ap-training-job\"\n",
    "MACHINE_TYPE = \"n2-highmem-2\"\n",
    "REPLICA_COUNT = 1\n",
    "EXECUTOR_IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-13.py310:latest\"\n",
    "WORKING_DIRECTORY = \".\"\n",
    "SCRIPT_PATH = \"train.py\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab70e7-a957-4249-8957-2ef2fe4594bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the gcloud CLI to create a custom training job using auto packagin\n",
    "\n",
    "! gcloud ai custom-jobs create \\\n",
    "  --region=$LOCATION \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --worker-pool-spec=machine-type=$MACHINE_TYPE,replica-count=$REPLICA_COUNT,executor-image-uri=$EXECUTOR_IMAGE_URI,local-package-path=$WORKING_DIRECTORY,script=$SCRIPT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646e5dae-a71e-4c1c-afeb-4b97f6f4098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize aiplatform\n",
    "aiplatform.init(project=PROJECT, location=LOCATION)\n",
    "\n",
    "# Create the model\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_NAME,\n",
    "    artifact_uri=f'gs://{BUCKET_NAME}/{GCS_FOLDER}',\n",
    "    serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-13:latest',\n",
    ")\n",
    "\n",
    "print(f'Model ID: {model.resource_name}')\n",
    "\n",
    "# Deploy the model to the endpoint\n",
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=f'{MODEL_NAME}-deployed',\n",
    "    machine_type='n2-highmem-2'\n",
    ")\n",
    "\n",
    "print(f'Endpoint ID: {endpoint.resource_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91c2f1-702d-4c93-b9b8-0b0d1dfb3794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy the pickled preprocessing stuff\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "pkls = [\n",
    "    \"scaler.pkl\",\n",
    "    \"label_encoder.pkl\",\n",
    "    \"categorical_encoder.pkl\"\n",
    "]\n",
    "\n",
    "for pkl in pkls:\n",
    "    blob = bucket.blob(f\"{GCS_FOLDER}/{pkl}\")\n",
    "    blob.download_to_filename(pkl)\n",
    "\n",
    "# load the pre-trained ML preprocessing objects (scaler, label_encoder, and categorical_encoder)\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "categorical_encoder = joblib.load('categorical_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e00556-820e-4dff-b2bc-9eddf6a7dfbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# populate the list of instances for prediction\n",
    "instances = [\n",
    "    [39,\"Private\", \"9th\",5,\"Married-civ-spouse\",\"Other-service\",\"Wife\",\"Black\",\"Female\",3411,0,34,\"United-States\"],\n",
    "    [77,\"Private\", \"9th\",5,\"Married-civ-spouse\",\"Priv-house-serv\",\"Wife\",\"Black\",\"Female\",0,0,10,\"United-States\"],\n",
    "    [27,\"Local-gov\",\"HS-grad\",9,\"Married-civ-spouse\",\"Exec-managerial\",\"Husband\",\"White\",\"Male\",0,0,80,\"United-States\"],\n",
    "    [40,\"Private\",\"Masters\",14,\"Married-civ-spouse\",\"Exec-managerial\",\"Husband\",\"White\",\"Male\",0,0,46,\"United-States\"]\n",
    "\n",
    "]\n",
    "\n",
    "# what is this code doing? why does it work?\n",
    "instances_numeric_features = np.array([[instance[0], instance[3], instance[9], instance[10], instance[11]] for instance in instances])\n",
    "instances_scaled_numeric_features = scaler.transform(instances_numeric_features)\n",
    "\n",
    "# what is this code doing? why does it work?\n",
    "instances_categorical_features = np.array([instance[1:3] + instance[4:9] + [instance[12]] for instance in instances])\n",
    "instances_categorical_encoded = categorical_encoder.transform(instances_categorical_features)\n",
    "\n",
    "# what is this code doing?\n",
    "instances_combined = np.hstack((instances_scaled_numeric_features, instances_categorical_encoded))\n",
    "\n",
    "# what is this code doing? why is it important?\n",
    "preprocessed_instances_as_list = instances_combined.tolist()\n",
    "\n",
    "# call the predict method and pass the instances for prediction\n",
    "response = endpoint.predict(instances=preprocessed_instances_as_list)\n",
    "\n",
    "# what is response.predictions?\n",
    "# what is a prediction?\n",
    "# what is argmax doing?\n",
    "# what is inverse_transform doing?\n",
    "for prediction in response.predictions:\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    decoded_label = label_encoder.inverse_transform([predicted_label])[0]\n",
    "    print(f'Predicted Label: {decoded_label}')\n",
    "    print(f'Predicted Probabilities: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa86ee-0f0b-4852-8c91-0d58fd15dbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
